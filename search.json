[
  {
    "objectID": "posts/thesiswriting_aprimer.html",
    "href": "posts/thesiswriting_aprimer.html",
    "title": "PhD Thesis by Publication - Notes",
    "section": "",
    "text": "Note\n\n\n\nThese notes are based on a presentation I received at the Institute I currently work at, based at Monash University, Australia. Most people at my institute also do a thesis by publication, so this is from that POV."
  },
  {
    "objectID": "posts/thesiswriting_aprimer.html#thesis-by-publication",
    "href": "posts/thesiswriting_aprimer.html#thesis-by-publication",
    "title": "PhD Thesis by Publication - Notes",
    "section": "Thesis by Publication:",
    "text": "Thesis by Publication:\n\nThesis must reflect a sustained and cohesive theme with framing text linking chapter / papers / manuscripts\nIt is unlikely that your assessor will read the entire thesis in one sitting - so make sure you orient the research assessor at the very start of your thesis, and also throughout the chapters that you have compiled together\nAll theses must use approved thesis preliminary pages 1\nAt this point, generative AI is a thing - so you need to acknowledge this as part of your thesis (if you’ve used this)\nThe whole point of the thesis is to show that you have come of age as an independent reseracher. Introduction, linking text and conclusion should reflect this.\n\n1 Monash Specific Requirement\nAuthorship\n\nThere is no set number of publications, but usually in public health, 4 - 5 original research works, but atleast 1 needs to have been published, the rest, submitted (not necessarily accepted)\nBut this is up to the professional judgement of who’s reading your theses\nHow research fudning works in Australia is looking at your top 10 publications, so quality vs quantity - aim for high impact journals.\nPapers thata are submitted should have a substantial contribution from you (at least 50%)\nOther papers that are minor contributions should be kept in a minimum. You can still put them in though if they contribute to the narrative, or you can just chuck them into the appendix.\n\n\n\nExtra Things (Sans Submitted Publications)\n\nGeneral Introduction\nIntegrative Discussion with Conclusion\nFuture directions of the research\n\n\n\nOther Notes\n\nIntegrative discussion: needs to tie everything together, can be relatively brief, and should not repeat what youve said in your original individual papers\n\n\n\nChapter 1 : General Introduction\n\nUse your lit review to orient the reader to the thesis topic and why your reserach is significant\nOutline why your research is significant\nHypothesis and aims should be clearly stated\n\n\n\nChapter X : Integrated Discussion with a Conclusion\n\nShould provide a link between your project outcomes and highlight their significance\nAvoid repeating the discussion points in your indiviudal papers\nInstead summarise your studiesa nd then provide a more ‘overarching’ discussion\n\n\n\nWhat Are Assessors Assessing?\n\nWhether the student makes and original and substantial contribution to the discipline or area of professional practice\nCritically reflect on, and engage with complex ideas to create new knowedlege and understanding\nThesis presentation is appropriate (language, form etc.)"
  },
  {
    "objectID": "posts/thesiswriting_aprimer.html#post-phd",
    "href": "posts/thesiswriting_aprimer.html#post-phd",
    "title": "PhD Thesis by Publication - Notes",
    "section": "Post PhD",
    "text": "Post PhD\n\nDon’t forget about what you want to do post PhD!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Darren Rajit",
    "section": "",
    "text": "G’day! I’m a PhD Student at the Monash Centre for Health Research and Implementation (MCHRI), interested in Learning Health Systems, Complexity and Tech.\nIn practice, I split my time between:\n\nDeveloping and evaluating tools to streamline evidence synthesis during evidence-based guideline development and;\n\nUnderstanding how best to implement Learning Health Systems as a framework for Healthcare Improvement\n\nIn a previous life, I was a Biomedical Engineer (Materials) by training, but now find myself wearing hats that say things like “Data Analyst”, “Implementation Scientist”, and “Generally tries to be useful at all times”.\nOutside of work, I fall into rabbit holes, run, and lift.\nThis slice of the internet is where I maintain my CV, occasional side projects (eg: Apps to support automated citation searching 1), musings, and occassional commentary on my publications."
  },
  {
    "objectID": "drafts/ironman_analyses.html",
    "href": "drafts/ironman_analyses.html",
    "title": "Darren Rajit",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport matplotlib as mpl\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\n\n\n\nironman_path = \"../datasets/Half_Ironman_df6.csv\"\ndf = pd.read_csv(ironman_path)\ndf['count'] = 1\ndf_men = df[df['Gender']== 'M']\ndf_amateur = df_men[df_men['AgeGroup'] != '00']\ndf_pro = df_men[df_men['AgeGroup'] == '00']\n\n\ntime_cols = ['SwimTime', 'BikeTime', 'RunTime', 'FinishTime']\noverall_rank_cols = []\nyearly_rank_cols = []\nfor col in time_cols: \n    #assign a percentile rank to each row for each time \n    df_amateur[col + '_overall_rank'] = df_amateur[col].rank(pct=True)*100\n    overall_rank_cols.append(col + '_overall_rank')\n\n\n\n\n\n#set order of age groups \nage_order = ['18-24','25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64']\ndf_amateur_workingage = df_amateur[df_amateur['AgeGroup'].isin(age_order)]\ndf_amateur_workingage['AgeGroup'] = pd.Categorical(df_amateur_workingage['AgeGroup'], categories=age_order, ordered=True)\ndf_amateur_workingage['Performance_category'] = pd.cut(df_amateur_workingage['FinishTime_overall_rank'], bins=[0,5,20,40,60,100], labels=['Elite', 'Sub-Elite', 'Above Average', 'Average', 'Below Average'])\n\n\nage_dist_year = df_amateur_workingage[['EventYear', 'AgeGroup', 'count']].groupby(['EventYear', 'AgeGroup']).sum()\n\n#normalize counts and plot distributions \ntotal_agegroup_counts_year = age_dist_year.groupby('EventYear')['count'].sum().reset_index()\nage_dist_year['total'] = (age_dist_year.index.get_level_values('EventYear').map(total_agegroup_counts_year.set_index('EventYear')['count'])).astype(int)\nage_dist_year['proportion'] = age_dist_year['count']/age_dist_year['total']*100\nage_dist_year.reset_index(inplace=True)\npivot_df = age_dist_year.pivot(index='EventYear', columns='AgeGroup', values='proportion')\n#set order of age groups \nage_order = ['18-24','25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64']\npalette = sns.color_palette(\"pastel\", len(age_order))\nsns.set_palette(palette)\n\nplt.figure(figsize=(12, 8))\nfor column in pivot_df.columns:\n    plt.plot(pivot_df.index, pivot_df[column], marker='', linewidth=2, label=column)\n\nplt.title('Normalized Proportion of Age Groups by Year')\nplt.xlabel('Event Year')\nplt.ylabel('Proportion (%)')\nplt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(True)\nplt.xticks(rotation=45)\nplt.tight_layout()  # Adjust layout to make room for the legend\nplt.show()\n\n#agestandardize to 2019 \n\n\n\n\n\n\n\n\n\npivot_df\n\n\n\n\n\n\n\nAgeGroup\n18-24\n25-29\n30-34\n35-39\n40-44\n45-49\n50-54\n55-59\n60-64\n\n\nEventYear\n\n\n\n\n\n\n\n\n\n\n\n\n\n2004\n3.030303\n9.696970\n18.354978\n27.445887\n20.346320\n11.861472\n6.060606\n1.991342\n1.212121\n\n\n2005\n5.073052\n11.891234\n21.063312\n24.391234\n17.775974\n10.146104\n5.357143\n2.922078\n1.379870\n\n\n2006\n4.314721\n10.821412\n16.289802\n24.988463\n20.027688\n11.998154\n5.952930\n3.737886\n1.868943\n\n\n2007\n5.250644\n11.016445\n17.356846\n24.152962\n19.556172\n11.709927\n5.825243\n3.269269\n1.862493\n\n\n2008\n5.475458\n11.339705\n17.058156\n24.364167\n19.536692\n11.728495\n6.107241\n2.932124\n1.457962\n\n\n2009\n4.854687\n12.181744\n16.856324\n22.365944\n19.762587\n12.771183\n6.819484\n2.979943\n1.408105\n\n\n2010\n3.882320\n11.094072\n15.912668\n21.816861\n21.760362\n13.664797\n7.405464\n3.071149\n1.392308\n\n\n2011\n3.748437\n10.718752\n17.011124\n21.282828\n21.398012\n13.512802\n7.783190\n3.142895\n1.401961\n\n\n2012\n4.069457\n10.658680\n17.529223\n20.480671\n21.256730\n13.634379\n7.923073\n3.138187\n1.309599\n\n\n2013\n4.022096\n10.921555\n17.115538\n19.742213\n20.991215\n14.202680\n8.070814\n3.605023\n1.328867\n\n\n2014\n3.769255\n10.626128\n16.781117\n19.858611\n20.675227\n14.646780\n8.343316\n3.814810\n1.484756\n\n\n2015\n3.638609\n9.990204\n16.649867\n19.551669\n20.088303\n15.399140\n9.050384\n4.067349\n1.564474\n\n\n2016\n3.149912\n9.582122\n16.192765\n19.711054\n19.971508\n15.853167\n9.502979\n4.316919\n1.719573\n\n\n2017\n3.295002\n9.630507\n15.885220\n19.605731\n19.829258\n15.575514\n9.746310\n4.695411\n1.737046\n\n\n2018\n3.388878\n9.641831\n15.774756\n19.148311\n18.867394\n15.893507\n10.178127\n5.171423\n1.935772\n\n\n2019\n3.383428\n9.849946\n16.328016\n19.096905\n18.364542\n15.385415\n10.147974\n5.404937\n2.038836\n\n\n2020\n3.674685\n10.229530\n15.824321\n19.068638\n18.836901\n14.864268\n9.854337\n5.561686\n2.085632\n\n\n\n\n\n\n\n\n#\n\n\n## What does average mean? \n#45 - 55th percentile \ndf_amateur_yearly_avg = pd.DataFrame(df_amateur['EventYear'].unique()).rename(columns={0:'EventYear'})\nfor i in range (0,60,5): \n    for col in time_cols: \n        colname = col + '_'+str(100-i)+'_percentile'\n        quantile_data = df_amateur.groupby(['EventYear'])[col].quantile(i/100).reset_index()\n        #convert to hh:mm:ss format \n        quantile_data.rename(columns={col:colname}, inplace=True)\n        df_amateur_yearly_avg = pd.merge(df_amateur_yearly_avg, quantile_data, on='EventYear', how='left')\n#sort by event year \ndf_amateur_yearly_avg = df_amateur_yearly_avg.sort_values(by='EventYear')\n\n\ndf_pro_yearly_avg = pd.DataFrame(df_pro['EventYear'].unique()).rename(columns={0:'EventYear'})\nfor i in range (0,60,5): \n    for col in time_cols: \n        colname = col + '_'+str(100-i)+'_percentile'\n        quantile_data = df_pro.groupby(['EventYear'])[col].quantile(i/100).reset_index()\n        #convert to hh:mm:ss format \n        quantile_data.rename(columns={col:colname}, inplace=True)\n        df_pro_yearly_avg = pd.merge(df_pro_yearly_avg, quantile_data, on='EventYear', how='left')\n#sort by event year \ndf_pro_yearly_avg = df_pro_yearly_avg.sort_values(by='EventYear')\n\n\n#scatter plot of event year by 50th percentile times \nsns.scatterplot(data=df_amateur_yearly_avg, x='EventYear', y='FinishTime_50_percentile', label='Amateur')\n\n\n\n\n\n\n\n\n\ndf_amateur_yearly_avg.reset_index(drop=True)\nyoy_change_df = pd.DataFrame(df_amateur_yearly_avg['EventYear']).rename(columns={0:'EventYear'}).reset_index(drop=True)\nfor j in [50,65,80,90,95]: \n    colname = 'FinishTime_'+str(j)+'_percentile'\n    yoy_change_list = [0]\n    for i in range (1,len(df_amateur_yearly_avg['EventYear'])):\n        yoy_change = (df_amateur_yearly_avg.loc[i, colname]/df_amateur_yearly_avg.loc[i-1, colname]-1)*100\n        yoy_change_list.append(yoy_change)\n    yoy_colname = 'yoy_change_{}pct'.format(j)\n    yoy_change_df[yoy_colname] = yoy_change_list\n\nyoy_change_df_long = pd.melt(yoy_change_df, id_vars=['EventYear'], value_vars=['yoy_change_50pct', 'yoy_change_65pct', 'yoy_change_80pct', 'yoy_change_90pct', 'yoy_change_95pct'], var_name = 'Average Finish Time (percentile)', value_name = 'YoY Change (%)')\nplt.figure(figsize=(8,5))\nsns.lineplot(data=yoy_change_df_long, x='EventYear', y='YoY Change (%)', hue='Average Finish Time (percentile)')\nlegend_labels = ['50th percentile', '65th percentile', '80th percentile', '90th percentile', '95th percentile']\nplt.legend(loc='lower center', labels = legend_labels)\n\n\n#average yearly change in finish time for amateur athletes by percentile \n#remove first row \n\navg_change_df_pct = yoy_change_df[1:][['yoy_change_50pct','yoy_change_65pct','yoy_change_80pct','yoy_change_90pct','yoy_change_95pct']].agg(['mean', 'median'])\n\n\n\n\n\n\n\n\n\navg_change_df_pct\n\n\n\n\n\n\n\n\nyoy_change_50pct\nyoy_change_65pct\nyoy_change_80pct\nyoy_change_90pct\nyoy_change_95pct\n\n\n\n\nmean\n-0.019772\n-0.021941\n-0.054345\n-0.092420\n-0.117380\n\n\nmedian\n-0.072977\n-0.137429\n-0.138809\n-0.145364\n-0.540181\n\n\n\n\n\n\n\n\n\n#plot yoy_change distributions \n\n\ndf_amateur_yearly_avg.columns\n\nIndex(['EventYear', 'SwimTime_100_percentile', 'BikeTime_100_percentile',\n       'RunTime_100_percentile', 'FinishTime_100_percentile',\n       'SwimTime_95_percentile', 'BikeTime_95_percentile',\n       'RunTime_95_percentile', 'FinishTime_95_percentile',\n       'SwimTime_90_percentile', 'BikeTime_90_percentile',\n       'RunTime_90_percentile', 'FinishTime_90_percentile',\n       'SwimTime_85_percentile', 'BikeTime_85_percentile',\n       'RunTime_85_percentile', 'FinishTime_85_percentile',\n       'SwimTime_80_percentile', 'BikeTime_80_percentile',\n       'RunTime_80_percentile', 'FinishTime_80_percentile',\n       'SwimTime_75_percentile', 'BikeTime_75_percentile',\n       'RunTime_75_percentile', 'FinishTime_75_percentile',\n       'SwimTime_70_percentile', 'BikeTime_70_percentile',\n       'RunTime_70_percentile', 'FinishTime_70_percentile',\n       'SwimTime_65_percentile', 'BikeTime_65_percentile',\n       'RunTime_65_percentile', 'FinishTime_65_percentile',\n       'SwimTime_60_percentile', 'BikeTime_60_percentile',\n       'RunTime_60_percentile', 'FinishTime_60_percentile',\n       'SwimTime_55_percentile', 'BikeTime_55_percentile',\n       'RunTime_55_percentile', 'FinishTime_55_percentile',\n       'SwimTime_50_percentile', 'BikeTime_50_percentile',\n       'RunTime_50_percentile', 'FinishTime_50_percentile',\n       'SwimTime_45_percentile', 'BikeTime_45_percentile',\n       'RunTime_45_percentile', 'FinishTime_45_percentile'],\n      dtype='object')\n\n\n\ndef seconds_to_hhmmss(seconds):\n    hours = seconds // 3600\n    minutes = (seconds % 3600) // 60\n    seconds = seconds % 60\n    return f'{int(hours):02}:{int(minutes):02}:{int(seconds):02}'\n\n#plot above average 55th to 69th percentile finish times \n#create plot, size 5, 10\naxs = plt.figure(layout = 'constrained', figsize= (12,6)).subplot_mosaic(\n    \"\"\"ABC;DDD\"\"\"\n    )\n#plot above average 55th to 69th percentile finish times\n\nsns.lineplot(data = df_amateur_yearly_avg, x = 'EventYear', y = 'SwimTime_50_percentile', label = 'Swim (Amateur)', color = 'blue', ax=axs['A'])\naxs['A'].fill_between(df_amateur_yearly_avg['EventYear'], df_amateur_yearly_avg['SwimTime_45_percentile'], df_amateur_yearly_avg['SwimTime_55_percentile'], alpha=0.2, color = 'blue')\nsns.lineplot(data = df_pro_yearly_avg, x = 'EventYear', y = 'SwimTime_50_percentile', label = 'Swim (Pro)', linestyle='dotted', color = 'blue', ax = axs['A'])\naxs['A'].fill_between(df_pro_yearly_avg['EventYear'], df_pro_yearly_avg['SwimTime_45_percentile'], df_pro_yearly_avg['SwimTime_55_percentile'], alpha=0.2, color = 'blue')\n\nsns.lineplot(data = df_amateur_yearly_avg, x = 'EventYear', y = 'BikeTime_50_percentile', label = 'Bike (Amateur)', color = 'orange', ax = axs['B'])\naxs['B'].fill_between(df_amateur_yearly_avg['EventYear'], df_amateur_yearly_avg['BikeTime_45_percentile'], df_amateur_yearly_avg['BikeTime_55_percentile'], alpha=0.2, color = 'orange')\nsns.lineplot(data = df_pro_yearly_avg, x = 'EventYear', y = 'BikeTime_50_percentile', label = 'Bike (Pro)', linestyle='dotted', color = 'orange', ax = axs['B'])\naxs['B'].fill_between(df_pro_yearly_avg['EventYear'], df_pro_yearly_avg['BikeTime_45_percentile'], df_pro_yearly_avg['BikeTime_55_percentile'], alpha=0.2, color = 'orange')\n\nsns.lineplot(data = df_amateur_yearly_avg, x = 'EventYear', y = 'RunTime_50_percentile', label = 'Run (Amateur)', color = 'green', ax = axs['C'])\naxs['C'].fill_between(df_amateur_yearly_avg['EventYear'], df_amateur_yearly_avg['RunTime_45_percentile'], df_amateur_yearly_avg['RunTime_55_percentile'], alpha=0.2, color = 'green')\nsns.lineplot(data = df_pro_yearly_avg, x = 'EventYear', y = 'RunTime_50_percentile', label = 'Run (Pro)', linestyle='dotted', color = 'green', ax = axs['C'])\naxs['C'].fill_between(df_pro_yearly_avg['EventYear'], df_pro_yearly_avg['RunTime_45_percentile'], df_pro_yearly_avg['RunTime_55_percentile'], alpha=0.2, color = 'green')\n\nsns.lineplot(data = df_amateur_yearly_avg, x = 'EventYear', y = 'FinishTime_50_percentile', label = 'Finish (Amateur)', color = 'red', ax = axs['D'])\naxs['D'].fill_between(df_amateur_yearly_avg['EventYear'], df_amateur_yearly_avg['FinishTime_45_percentile'], df_amateur_yearly_avg['FinishTime_55_percentile'], alpha=0.2, color = 'red')\nsns.lineplot(data = df_pro_yearly_avg, x = 'EventYear', y = 'FinishTime_50_percentile', label = 'Finish (Pro)', linestyle='dotted', color = 'red', ax = axs['D'])\naxs['D'].fill_between(df_pro_yearly_avg['EventYear'], df_pro_yearly_avg['FinishTime_45_percentile'], df_pro_yearly_avg['FinishTime_55_percentile'], alpha=0.2, color = 'red')\n\nfrom matplotlib.ticker import FuncFormatter, MultipleLocator\nformatter = FuncFormatter(lambda x, _: seconds_to_hhmmss(x))\naxs['A'].yaxis.set_major_formatter(formatter)\naxs['A'].yaxis.set_major_locator(MultipleLocator(base=120))\naxs['A'].set_ylabel('Swim Finish Time')\naxs['A'].set_ylim(1200,2640)\naxs['B'].yaxis.set_major_formatter(formatter)\naxs['B'].yaxis.set_major_locator(MultipleLocator(base=300))\naxs['B'].set_ylabel('Bike Finish Time')\naxs['B'].set_ylim(7200,10800)\naxs['C'].yaxis.set_major_formatter(formatter)\naxs['C'].yaxis.set_major_locator(MultipleLocator(base=300))\naxs['C'].set_ylabel('Run Finish Time')\naxs['C'].set_ylim(4500,8100)\naxs['D'].yaxis.set_major_formatter(formatter)\naxs['D'].yaxis.set_major_locator(MultipleLocator(base=600))\naxs['D'].set_ylim(13500,21600)\n\nplt.ylabel('Finish Time')\nplt.xlabel('Year')\n# sns.move_legend(, \"upper left\", bbox_to_anchor=(1, 1))\n#Convert seconds to hours, mm and\n\n# # Combine legends from all subplots into one\n# handles, labels = axs[0].get_legend_handles_labels()\n# plt.tight_layout(rect=[0.05, 0.1, 0.95, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\n#find age group distributions where the middle 50% of finish times  are \ndf_working_age = df_amateur[df_amateur['AgeGroup'].isin(['18-24','25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-64'])]\nplt.figure(figsize=(10,5))\nagegrp_mid = df_working_age[['EventYear', 'AgeGroup', 'FinishTime']].groupby(['EventYear', 'AgeGroup'])['FinishTime'].quantile([0.45, 0.5, 0.55]).unstack().reset_index()\nagegrp_mid.rename(columns={0.45:'FinishTime_45pct', 0.5:'FinishTime_50pct', 0.55:'FinishTime_55pct'}, inplace=True)\n\n#plot average finish times across the years, across the different age groups \nagegrp_plot = sns.lineplot(data = agegrp_mid, x = 'EventYear', y = 'FinishTime_50pct', hue = 'AgeGroup')\n\n\n\n\n\n\n\n\n\n#find age group distributions where the middle 50% of finish times  are \nplt.figure(figsize=(10,10))\nagegrp_abvabg = df_working_age[['EventYear', 'AgeGroup', 'FinishTime']].groupby(['EventYear', 'AgeGroup'])['FinishTime'].quantile([0.2, 0.1, 0.01]).unstack().reset_index()\nagegrp_abvabg.rename(columns={0.2:'FinishTime_top60pct', 0.1:'FinishTime_top65pct', 0.01:'FinishTime_top70pct'}, inplace=True)\n#plot average finish times across the years, across the different age groups \nagegrp_plot = sns.lineplot(data = agegrp_abvabg, x = 'EventYear', y = 'FinishTime_top70pct', hue = 'AgeGroup')\n\n\n\n\n\n\n\n\n\ndf_pro\n\n\n\n\n\n\n\n\nGender\nAgeGroup\nAgeBand\nCountry\nCountryISO2\nEventYear\nEventLocation\nSwimTime\nTransition1Time\nBikeTime\nTransition2Time\nRunTime\nFinishTime\ncount\n\n\n\n\n424\nM\n00\n0\nUnited Arab Emirates\nAE\n2011\nIRONMAN 70.3 Asia-Pacific\n1433\n96\n8638\n105\n4837\n15109\n1\n\n\n477\nM\n00\n0\nUnited Arab Emirates\nAE\n2012\nIRONMAN 70.3 World Championship\n1449\n163\n7985\n74\n4936\n14607\n1\n\n\n802\nM\n00\n0\nArgentina\nAR\n2019\nIRONMAN 70.3 South American Championship Bueno...\n1385\n82\n7736\n67\n4735\n14006\n1\n\n\n803\nM\n00\n0\nArgentina\nAR\n2019\nIRONMAN 70.3 South American Championship Bueno...\n1620\n94\n7741\n74\n4635\n14164\n1\n\n\n835\nM\n00\n0\nArgentina\nAR\n2019\nIRONMAN 70.3 South American Championship Bueno...\n1752\n123\n8504\n94\n5813\n16285\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n838622\nM\n00\n0\nSouth Africa\nZA\n2015\nIRONMAN 70.3 South Africa\n1671\n179\n10014\n157\n5053\n17074\n1\n\n\n839832\nM\n00\n0\nSouth Africa\nZA\n2015\nIRONMAN 70.3 St. George\n1559\n120\n7968\n61\n4776\n14484\n1\n\n\n839848\nM\n00\n0\nSouth Africa\nZA\n2015\nIRONMAN 70.3 Budapest\n1693\n114\n7923\n104\n4190\n14024\n1\n\n\n839908\nM\n00\n0\nSouth Africa\nZA\n2015\nIRONMAN 70.3 Switzerland\n1437\n115\n8780\n80\n5366\n15778\n1\n\n\n839946\nM\n00\n0\nSouth Africa\nZA\n2015\nIRONMAN 70.3 Busselton\n1545\n95\n7693\n60\n4267\n13660\n1\n\n\n\n\n10282 rows × 14 columns\n\n\n\n\nagegrp_abvabg\n\n\n\n\n\n\n\n\nEventYear\nAgeGroup\nFinishTime_top60pct\nFinishTime_top65pct\nFinishTime_top70pct\n\n\n\n\n0\n2004\n18-24\n18329.2\n17289.2\n17015.96\n\n\n1\n2004\n25-29\n18193.2\n16926.9\n15496.41\n\n\n2\n2004\n30-34\n17947.4\n17352.0\n15587.51\n\n\n3\n2004\n35-39\n18296.0\n17495.6\n16139.28\n\n\n4\n2004\n40-44\n18149.4\n17504.4\n16429.06\n\n\n...\n...\n...\n...\n...\n...\n\n\n148\n2020\n40-44\n17647.2\n16801.2\n15318.56\n\n\n149\n2020\n45-49\n17813.6\n17092.2\n15888.42\n\n\n150\n2020\n50-54\n18107.4\n17434.8\n16088.40\n\n\n151\n2020\n55-59\n18803.4\n17844.8\n16724.53\n\n\n152\n2020\n60-64\n19162.4\n18302.8\n16914.76\n\n\n\n\n153 rows × 5 columns\n\n\n\n\nagegrp_mid\n\n\n\n\n\n\n\n\nEventYear\nAgeGroup\nFinishTime_45pct\nFinishTime_50pct\nFinishTime_55pct\n\n\n\n\n0\n2004\n18-24\n19629.80\n20234.0\n20777.50\n\n\n1\n2004\n25-29\n19729.25\n19968.0\n20438.15\n\n\n2\n2004\n30-34\n19790.70\n20066.0\n20358.25\n\n\n3\n2004\n35-39\n20033.60\n20465.0\n20783.80\n\n\n4\n2004\n40-44\n19750.80\n20085.0\n20642.30\n\n\n...\n...\n...\n...\n...\n...\n\n\n148\n2020\n40-44\n19558.70\n19917.0\n20288.60\n\n\n149\n2020\n45-49\n19595.20\n19967.0\n20349.90\n\n\n150\n2020\n50-54\n20023.20\n20372.0\n20641.80\n\n\n151\n2020\n55-59\n20578.00\n20884.5\n21291.00\n\n\n152\n2020\n60-64\n20684.40\n21039.0\n21312.40\n\n\n\n\n153 rows × 5 columns\n\n\n\n\n\nyoy_change_df = pd.DataFrame(df_amateur_yearly_avg['EventYear']).rename(columns={0:'EventYear'}).reset_index(drop=True)\nfor j in [50,65,80,90,95]: \n    colname = 'FinishTime_'+str(j)+'_percentile'\n    yoy_change_list = [0]\n    for i in range (1,len(df_amateur_yearly_avg['EventYear'])):\n        yoy_change = (df_amateur_yearly_avg.loc[i, colname]/df_amateur_yearly_avg.loc[i-1, colname]-1)*100\n        yoy_change_list.append(yoy_change)\n    yoy_colname = 'yoy_change_{}pct'.format(j)\n    yoy_change_df[yoy_colname] = yoy_change_list\n\nyoy_change_df_long = pd.melt(yoy_change_df, id_vars=['EventYear'], value_vars=['yoy_change_50pct', 'yoy_change_65pct', 'yoy_change_80pct', 'yoy_change_90pct', 'yoy_change_95pct'], var_name = 'Average Finish Time (percentile)', value_name = 'YoY Change (%)')\nsns.lineplot(data=yoy_change_df_long, x='EventYear', y='YoY Change (%)', hue='Average Finish Time (percentile)')\nlegend_labels = ['50th percentile', '65th percentile', '80th percentile', '90th percentile', '95th percentile']\nplt.legend(loc='upper right', labels = legend_labels, bbox_to_anchor = (1.35,1))\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\n\n\n\n\ndf_amateur_yearly_avg\n\n\n\n\n\n\n\n\nEventYear\nSwimTime_100_percentile\nBikeTime_100_percentile\nRunTime_100_percentile\nFinishTime_100_percentile\nSwimTime_95_percentile\nBikeTime_95_percentile\nRunTime_95_percentile\nFinishTime_95_percentile\nSwimTime_90_percentile\n...\nRunTime_55_percentile\nFinishTime_55_percentile\nSwimTime_50_percentile\nBikeTime_50_percentile\nRunTime_50_percentile\nFinishTime_50_percentile\nSwimTime_45_percentile\nBikeTime_45_percentile\nRunTime_45_percentile\nFinishTime_45_percentile\n\n\n\n\n13\n2004\n1572.0\n8166.0\n4759.0\n14849.0\n1861.4\n8732.20\n5680.70\n16996.60\n1949.4\n...\n7228.90\n20186.90\n2431.0\n9949.0\n7431.0\n20533.0\n2496.0\n10073.4\n7598.1\n20866.00\n\n\n14\n2005\n1422.0\n7966.0\n4623.0\n15314.0\n1685.0\n8827.45\n5499.90\n16904.80\n1800.9\n...\n7167.05\n20248.05\n2209.0\n10367.0\n7361.5\n20576.5\n2257.0\n10527.9\n7537.8\n20935.80\n\n\n15\n2006\n1259.0\n7573.0\n4496.0\n14355.0\n1677.0\n8125.00\n5418.50\n15962.00\n1784.0\n...\n7022.00\n19632.50\n2233.0\n10008.0\n7214.0\n20046.0\n2293.0\n10157.0\n7418.5\n20462.50\n\n\n9\n2007\n1205.0\n7552.0\n4254.0\n14273.0\n1693.0\n8755.00\n5405.20\n16538.00\n1786.0\n...\n7037.00\n19918.80\n2251.0\n10165.0\n7224.0\n20276.0\n2305.0\n10315.0\n7426.2\n20639.00\n\n\n10\n2008\n1308.0\n7413.0\n4021.0\n14913.0\n1739.0\n8945.00\n5531.60\n17029.00\n1864.0\n...\n7133.00\n20524.40\n2335.0\n10556.0\n7313.0\n20862.0\n2384.0\n10724.8\n7503.8\n21192.80\n\n\n16\n2009\n1214.0\n7373.0\n4182.0\n13895.0\n1584.0\n8387.00\n5401.00\n16233.50\n1685.0\n...\n7022.50\n19878.00\n2181.0\n10277.0\n7214.0\n20240.0\n2234.0\n10424.0\n7410.0\n20605.50\n\n\n11\n2010\n1230.0\n6887.0\n4030.0\n14272.0\n1709.0\n8801.00\n5579.20\n16937.00\n1833.0\n...\n7424.00\n20555.00\n2362.0\n10340.0\n7617.0\n20943.0\n2418.0\n10494.2\n7833.2\n21299.20\n\n\n6\n2011\n1210.0\n7156.0\n4068.0\n14009.0\n1673.0\n8832.00\n5470.00\n16805.50\n1795.0\n...\n7125.00\n20264.00\n2304.0\n10369.0\n7314.0\n20613.0\n2358.0\n10513.0\n7503.0\n20972.00\n\n\n12\n2012\n1201.0\n6511.0\n4010.0\n13449.0\n1661.0\n8733.00\n5521.00\n16766.80\n1775.0\n...\n7077.00\n20184.20\n2245.0\n10372.0\n7253.0\n20526.0\n2296.0\n10523.0\n7438.0\n20867.00\n\n\n8\n2013\n1242.0\n6648.0\n4017.0\n14120.0\n1678.0\n8772.00\n5461.00\n16724.35\n1792.0\n...\n7049.00\n20120.00\n2258.0\n10321.0\n7222.0\n20462.5\n2310.0\n10475.0\n7412.0\n20812.00\n\n\n7\n2014\n1201.0\n6825.0\n4062.0\n13979.0\n1614.0\n8758.00\n5440.00\n16635.45\n1752.0\n...\n7055.00\n20174.00\n2244.5\n10402.0\n7240.0\n20543.5\n2298.0\n10556.0\n7444.0\n20908.00\n\n\n2\n2015\n1202.0\n6657.0\n4002.0\n14275.0\n1693.0\n8742.00\n5526.00\n16766.00\n1800.0\n...\n7118.00\n20200.00\n2256.0\n10316.0\n7297.0\n20558.0\n2309.0\n10470.0\n7490.0\n20915.75\n\n\n3\n2016\n1201.0\n7417.0\n4033.0\n14112.0\n1663.0\n8709.00\n5478.00\n16665.00\n1784.0\n...\n7071.00\n20175.00\n2264.0\n10282.0\n7257.0\n20532.0\n2318.0\n10432.0\n7455.0\n20894.00\n\n\n4\n2017\n1201.0\n7159.0\n4009.0\n14106.0\n1686.0\n8702.00\n5492.00\n16705.00\n1812.0\n...\n7094.00\n20171.00\n2283.0\n10283.0\n7279.0\n20528.0\n2334.0\n10436.0\n7474.0\n20888.00\n\n\n5\n2018\n1201.0\n7456.0\n4081.0\n14102.0\n1682.0\n8639.00\n5428.00\n16577.00\n1795.0\n...\n7001.00\n20059.00\n2262.0\n10262.0\n7173.0\n20417.0\n2315.0\n10419.0\n7360.0\n20781.00\n\n\n0\n2019\n1201.0\n6954.0\n4200.0\n13864.0\n1684.0\n8639.00\n5366.00\n16601.45\n1804.0\n...\n6950.00\n19993.00\n2262.0\n10262.0\n7128.0\n20344.0\n2315.0\n10416.0\n7322.0\n20702.00\n\n\n1\n2020\n1288.0\n7067.0\n4384.0\n13900.0\n1680.0\n8407.00\n5346.95\n16172.95\n1770.0\n...\n6825.00\n19530.55\n2199.0\n10031.0\n6999.0\n19877.5\n2250.0\n10174.0\n7182.0\n20267.45\n\n\n\n\n17 rows × 49 columns\n\n\n\n\nfrom IPython.display import Markdown \nfrom tabulate import tabulate\nfinishers_yearly = df_amateur.groupby('EventYear')['count'].sum().reset_index()\nyoy_change_df['total_finishers'] = finishers_yearly['count']\nyoy_change_df\n\n#plot regression line for each percentile vs event year \nfrom scipy.stats import pearsonr, linregress\nfinish_percentile_col = ['FinishTime_50_percentile', 'FinishTime_65_percentile', 'FinishTime_80_percentile', 'FinishTime_90_percentile', 'FinishTime_95_percentile']\n\n#calculate correlation coefficient for each percentile\ndf_eventyear_finish_corr = pd.DataFrame()\nfor col in finish_percentile_col: \n    pro_corr = pearsonr(df_pro_yearly_avg['EventYear'], df_pro_yearly_avg[col])\n    amateur_corr = pearsonr(df_amateur_yearly_avg['EventYear'], df_amateur_yearly_avg[col])\n    pro_results = (pro_corr[0], pro_corr[1])\n    amateur_results = (amateur_corr[0], amateur_corr[1])\n    df_eventyear_finish_corr = df_eventyear_finish_corr.append({'Percentile':col, 'R Value (Pro)':pro_results[0], 'P-Value (Pro)':pro_results[1], 'R Value (Amateur)':amateur_results[0], 'P-Value (Amateur)':amateur_results[1]}, ignore_index=True)\n    \nMarkdown(tabulate(df_eventyear_finish_corr))\n\n\n#plot regression line for each avg percentile against event years \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPercentile\nR Value (Pro)\nP-Value (Pro)\nR Value (Amateur)\nP-Value (Amateur)\n\n\n\n\n0\nFinishTime_50_percentile\n-0.705056\n0.00157193\n-0.224363\n0.386641\n\n\n1\nFinishTime_65_percentile\n-0.720402\n0.00110658\n-0.173852\n0.504567\n\n\n2\nFinishTime_80_percentile\n-0.737097\n0.000735811\n-0.109345\n0.676126\n\n\n3\nFinishTime_90_percentile\n-0.724633\n0.00100056\n-0.115874\n0.657861\n\n\n4\nFinishTime_95_percentile\n-0.720559\n0.00110249\n-0.200382\n0.440627\n\n\n\n\n\n\ndf_eventyear_finish_corr\n\n\n\n\n\n\n\n\nPercentile\nR Value (Pro)\nP-Value (Pro)\nR Value (Amateur)\nP-Value (Amateur)\n\n\n\n\n0\nFinishTime_50_percentile\n-0.705056\n0.001572\n-0.224363\n0.386641\n\n\n1\nFinishTime_65_percentile\n-0.720402\n0.001107\n-0.173852\n0.504567\n\n\n2\nFinishTime_80_percentile\n-0.737097\n0.000736\n-0.109345\n0.676126\n\n\n3\nFinishTime_90_percentile\n-0.724633\n0.001001\n-0.115874\n0.657861\n\n\n4\nFinishTime_95_percentile\n-0.720559\n0.001102\n-0.200382\n0.440627\n\n\n\n\n\n\n\n\n#plot histogram of finish time \nsns.histplot(df['FinishTime'])\n\n\ntime_cols\n\n\n\n\n\n\n\n\n\n##00 = professionals \n\n#encoding pro status \ndf['Pro_status'] = df['AgeGroup'].apply(lambda x: 1 if x == '00' else 0)\ndf['AgeGroup'].unique()\n\narray(['40-44', '45-49', '35-39', '50-54', '25-29', '18-24', '30-34',\n       '55-59', '00', '60-64', '70-74', '65-69', '75-79', '80-84',\n       '85-89'], dtype=object)\n\n\n\nfinishers_yeargrp = df[['EventYear', 'Gender', 'count']].groupby(['EventYear', 'Gender']).sum().reset_index()\nyeargrp = df[['EventYear', 'Gender', 'count']].groupby(['EventYear']).sum().reset_index() \nyeargrp['Gender'] = 'Total'\nfinishers_yeargrp = pd.concat([finishers_yeargrp, yeargrp]).reset_index(drop=True)\n\n\n#plot number of finishers by year \nsns.set_theme(style=\"darkgrid\")\nfinisher_countplt = sns.lineplot(data=finishers_yeargrp, x='EventYear', y='count', hue='Gender')\nfinisher_countplt.set(title='Number of Finishers by Year', xlabel='Year', ylabel='Number of Finishers')\n\n# Formatting y-axis\nfinisher_countplt.get_yaxis().set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n\n\n\n\n\n\n\n\n\n#figure out the age"
  },
  {
    "objectID": "drafts/15mc.html",
    "href": "drafts/15mc.html",
    "title": "15 Minute Cities and Conspiracy Theory",
    "section": "",
    "text": "Note\n\n\n\nStatement of Bias : As of 10th June 2024, I don’t drive, come from a middle class family, generally progressive in my politics, and am mostly able-bodied.1 I invite you to read on with these qualifiers in mind.\nA few days ago, this popped up on my twitter feed:\n15 minute cities were hot topic in 2023, and while the hoopla has calmed down somewhat, I’ve been marinating on its implications for a while. Late last year, I received a flyer in my mailbox decrying council plans in my neighbourhood for this very of model of development 2, with links to videos featuring scary-sounding phrases like “surveillance state”, “climate lockdowns”, and gasp the “World Economic Forum”. My poor council had to issue a follow up press statement on this soon after, but I’ve been puzzling why such an innocuous concept such as designing neighbourhoods where the things you need are close by (in this case, within 15 - 20 minutes by foot or bike), could be so controversial?\nTo what end? Try as I might, I’ve been unable to find a coherent answer."
  },
  {
    "objectID": "drafts/15mc.html#deconstructing-the-city-chrono-urbanism-and-the-rise-of-15-minute-cities",
    "href": "drafts/15mc.html#deconstructing-the-city-chrono-urbanism-and-the-rise-of-15-minute-cities",
    "title": "15 Minute Cities and Conspiracy Theory",
    "section": "Deconstructing the City : Chrono Urbanism and the Rise of 15 Minute Cities",
    "text": "Deconstructing the City : Chrono Urbanism and the Rise of 15 Minute Cities\nDefinition:\n\n\n\n15-minute Radii by various mode of transportation. Image source"
  },
  {
    "objectID": "blog_listing.html",
    "href": "blog_listing.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 18, 2024\n\n\nPhD Thesis by Publication - Notes\n\n\nDarren Rajit\n\n\n\n\nJun 12, 2024\n\n\nOn Having Little To Say\n\n\nDarren Rajit\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "drafts/garmin_analysis.html",
    "href": "drafts/garmin_analysis.html",
    "title": "Race Report Template",
    "section": "",
    "text": "Note: This is a template / demo race report template adapted from r/running, with code blocks for testing some analysis of my running data. Feel free to use it as you see fit."
  },
  {
    "objectID": "drafts/garmin_analysis.html#race-information",
    "href": "drafts/garmin_analysis.html#race-information",
    "title": "Race Report Template",
    "section": "Race Information",
    "text": "Race Information\n\nName: [Insert Race Name]\nDate: [Insert Race Date]\nDistance: [Insert Race Distance]\nLocation: [Insert Race Location]\nWebsite: [Insert Race Website]\nStrava: [Insert Strava Link]\nTime: [Insert Time]"
  },
  {
    "objectID": "drafts/garmin_analysis.html#goals",
    "href": "drafts/garmin_analysis.html#goals",
    "title": "Race Report Template",
    "section": "Goals",
    "text": "Goals\n\n\n\nGoal\nDescription\nCompleted?\n\n\n\n\nA\n[Insert Goal A]\n[Yes/No]\n\n\nB\n[Insert Goal B]\n[Yes/No]\n\n\nC\n[Insert Goal C]\n[Yes/No]"
  },
  {
    "objectID": "drafts/garmin_analysis.html#training",
    "href": "drafts/garmin_analysis.html#training",
    "title": "Race Report Template",
    "section": "Training",
    "text": "Training"
  },
  {
    "objectID": "drafts/garmin_analysis.html#pre-race",
    "href": "drafts/garmin_analysis.html#pre-race",
    "title": "Race Report Template",
    "section": "Pre-race",
    "text": "Pre-race"
  },
  {
    "objectID": "drafts/garmin_analysis.html#race",
    "href": "drafts/garmin_analysis.html#race",
    "title": "Race Report Template",
    "section": "Race",
    "text": "Race"
  },
  {
    "objectID": "drafts/garmin_analysis.html#post-race",
    "href": "drafts/garmin_analysis.html#post-race",
    "title": "Race Report Template",
    "section": "Post-race",
    "text": "Post-race"
  },
  {
    "objectID": "drafts/garmin_analysis.html#conclusion",
    "href": "drafts/garmin_analysis.html#conclusion",
    "title": "Race Report Template",
    "section": "Conclusion",
    "text": "Conclusion\n\n\nCode\nimport pandas as pd \nimport fitdecode \n\npath = '../datasets/11568900326_ACTIVITY.fit'\n\n# Open fit file and parse through the data\nwith fitdecode.FitReader(path) as fit:\n    \n    for frame in fit: \n\n        if isinstance(frame, fitdecode.records.FitDataMessage):\n            if frame.name == 'record': \n                if frame.has_field is True:\n                    print(frame.field_name, frame.value)\n\n\n\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\n~\\AppData\\Local\\Temp\\ipykernel_36744\\296927339.py in &lt;module&gt;\n      1 import pandas as pd\n----&gt; 2 import fitdecode\n      3 \n      4 path = '../datasets/11568900326_ACTIVITY.fit'\n      5 \n\nModuleNotFoundError: No module named 'fitdecode'"
  },
  {
    "objectID": "drafts/project_ironman_baseline.html",
    "href": "drafts/project_ironman_baseline.html",
    "title": "Project Ironman 70.3 - Benchmarks and Goal Setting",
    "section": "",
    "text": "So I’ve been in a bit of a situationship with my fitness for a long time. Grew up chubby, a sore spot I used to hold, though I wouldn’t say I was particularly sedentary 1. However, it’s only been in the past 8 years that I’ve been intentional with how I saw my fitness.\nAnd so, since 2018, I’ve made it a point to run a half marathon every year, interspersed with powerlifting style training through the year. This eventually led me to doing a full one last year with the Sydney Marathon. It was a bit of a dismal showing really, and looking back, my training, my commitment, nutrition, and my consistency could have definitely been improved. 2.\nBut I’ll admit, just running has been getting just a tad stale. The problem I’ve identified is consistency. The general cycle I’ve noticed is that I would train pretty consistently for an event in the leadup, I’d get sick or life would get in the way, I’d jump back in, get a niggle, and would end up sputtering to the starting line, with not enough miles in my legs. I’d reach the event, finish it, pretty well considering, and I’d resolve to not do it again. Then, inevitably, I’d catch the bug again, start training, but always seemingly from the same baseline, and so year-on-year, improvements would come few and far between. 3\nThe thing is, I’ve caught the bug again, and so I find myself wishing complete a full Ironman sometime before I die. I’ve got plenty of life left to live, but I’d prefer to complete one in a respectable way 4, within my physical prime. But what does this even mean?"
  },
  {
    "objectID": "drafts/project_ironman_baseline.html#now-this-is-average-performance",
    "href": "drafts/project_ironman_baseline.html#now-this-is-average-performance",
    "title": "Project Ironman 70.3 - Benchmarks and Goal Setting",
    "section": "Now This Is Average Performance",
    "text": "Now This Is Average Performance\nIt’s obvious that peak performance depends on the event you’re looking at. Things that require explosive power have a younger peak performance age, relative to things that require endurance, acquired knowledge and/or skill (Stiefel et al. 2013). Then again, there is the added confounder of training age, ie: how long you’ve been intentionally training over your lifetime. From a purely physiological development perspective though, I do think that there is a inflection point after which things start going downhill. I admit to a certain amount of anxiety when it comes to this, so in that sense, time (and youth) is of the essence.\nThankfully, I’ve managed to get my grubby hands on a dataset presenting Ironman 70.3 finish times from 2004 up to 2020. 16 years of data! 5, and it seems that the triathlon bug is hitting, and hitting good. Ironman 70.3 Triathlons are now big business, with 1572 finishers in 2004, up to a peak of 116,196 in 2019 (Figure 1), though I’d attribute the dip in 2020 to Covid.\n5 Shoutout to David who painstakingly compiled and cleaned the data available here\n\n\n\n\n\n\n\nFigure 1: Finisher counts by year, colored by Gender\n\n\n\n\n\nInterestingly, age distributions among male amateurs of working age have also started to stabilize. Funnily, it seems that doing a triathlon may come hand in hand with having a midlife crisis. Since 2013, almost 40% of finishers have been aged between 35 and 44 (Figure 2), with the 18-24 and 60-64 age groups being on the lower end of the working age distribution. Personally, I’d rack this up to the fact that triathlons are both an expensive and intensive sport, possibily acessible only to the young uns who can afford it, and the older ones who’ve probably had a lifetime worth of training to stand up to the rigous of the sport.\n\n\n\n\n\n\n\n\nFigure 2: Age Distribution of Ironman 70.3 Finishers, Male Age Groupers only\n\n\n\n\n\nThe thing is, with participation higher than ever before excepting the blip in 2020 (Figure 1), you’d think the overall standard would have increased. Interestingly, not exactly. At first glance, you’d see a raft of improvements from 2004 to 2010, there seems to have been a plateau in average (ie: 50th percentile) performance, across all disciplines 6, with now, slow and marginal improvements over time (Figure 3) 7. We can probably attribute this to the fact that as more people get involved with the Ironman 70.3, a whole initial raft of enthusiasts would have lead to initial improvement in time, but as the late majority joined the sport, what we know see is a gradul regresson to the mean. This seems to be especially the case for us amateurs, but something else seems to be happening with the pros…\n6 excepting 20207 I assume the sharp improvement in finish times here were due to an exceptionally more dedicated field of athletes, in both the pros and amateurs, possibly due to Covid restrictions meaning that only the more gungho folks would have still tried to participate at an Ironman.\n\n\n\n\n\n\n\nFigure 3: The average standard (45th - 55th Percentile) when it comes to finish times across the years for Men. Top row: Swim, Bike and Run finish times respectively. Bottom Row: Total Finish times. Dotted lines are the pros, solid lines are us mere mortals.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPercentile\nr, p (Pro)\nr, p (Amateur)\n\n\n\n\n50th\n-0.71, &lt;0.01\n-0.22, 0.39\n\n\n65th\n-0.72, &lt;0.01\n-0.17, 0.5\n\n\n80th\n-0.74, &lt;0.01\n-0.11, 0.68\n\n\n90th\n-0.72, &lt;0.01\n-0.12, 0.66\n\n\n95th\n-0.72, &lt;0.01\n-0.2, 0.44\n\n\n\n\n\nTable 1: Correlation analysis between Event Years, and Total Finish Times at various performance percentiles, pros and amateurs (Male, Aged 18 - 64)\n\n\n\n\nIn fact, Doing some quick correlation analysis (Table 1) of finish times across different performance percentiles vs year indicates a very weak, non-significant negative correlation (ie: faster times) for us amateurs. Eseentially, achieving average to elite times as an amateur age grouper has remained virtually unchanged over the years, and the time taken to be say, above average in one year would still make you above average in another. It’s a whole different ball game for the professionals though, with finish times being strongly correlated with the progression of time, from 2004 to 2020. The standard to go pro has never been harder, and it makes sense with the influx of Olympians into the sport over the past few years, with the Norweigians and their new-fangled approach to training widely hailed as one of the reasons for why World Records in the triathlon have been tumbling."
  },
  {
    "objectID": "drafts/project_ironman_baseline.html#age-groups-and-performance-how-long-do-i-have-at-my-theoretical-peak",
    "href": "drafts/project_ironman_baseline.html#age-groups-and-performance-how-long-do-i-have-at-my-theoretical-peak",
    "title": "Project Ironman 70.3 - Benchmarks and Goal Setting",
    "section": "Age Groups and Performance, How Long Do I Have At My Theoretical Peak?",
    "text": "Age Groups and Performance, How Long Do I Have At My Theoretical Peak?"
  },
  {
    "objectID": "drafts/project_ironman_baseline.html#my-current-baseline",
    "href": "drafts/project_ironman_baseline.html#my-current-baseline",
    "title": "Project Ironman 70.3 - Benchmarks and Goal Setting",
    "section": "My Current Baseline",
    "text": "My Current Baseline\nAs of writing (12th June 2024), I am 29 years old, and stand at 174 cm (5’9”) at a slightly tubby 77kg.\nEndurance"
  },
  {
    "objectID": "posts/on_having_little_to_say.html",
    "href": "posts/on_having_little_to_say.html",
    "title": "On Having Little To Say",
    "section": "",
    "text": "There was a time where writing was a source of joy for me. Catharsis, renewal, synthesis, and everything in between. Late nights where I would sift through the cobwebs in my head, squeeze out something that made sense to me, and regurgitate what was in my head into form. Over the past 5 years, I seem to have lost the capacity to do so. To create as it were, and it troubles me that I have settled into a steady rhythm of slack-jawed consuming.\nI wonder what my opinions are sometimes. Whether they are truly mine. I am one of the early generations that grew up on the internet, and I wonder how the cacophony of algorithmically constructed echo chambers that I’ve inardvatently found myself in has warped my point of view and sense of self. For a time there, I think I lost my voice. I think there is something there where losing the desire and ability to create comes hand in hand with losing who you are.\nI think I’m done with that. I’m done with taking without giving back. I’ve begun to notice how insidious that exchange is. Letting the Algorithm (TM) feed me my opinions, consuming without thought, and never sitting down and simply … ‘thinking’. I don’t think humans were meant to live this way. To hear and subsume the opinions of millions of faceless voices. Spend too long in the ether and you become as faceless and as formless as it is. Spending time alone and working out who you are, maybe that’s where the meat and potatoes is. At least meat and potatoes have form, and I think it’s time I assumed something of the sort.\nI have nothing to base this on, but it seems that culturally, humanity seems to have stagnated. Everything seem to be stuck in a grayscale of sameness. Our cars look the same, our neighbourhoods look the same, we’re dressing the same, so many things feel to me like they’re merging into one another, and because of it, losing form. And as we wade through this grimy monoculture, we all collectively start to lose ourselves. My gut tells me that the echo chambers we’ve built, the ones where we are fed well.. more of the same, has contributed to this. Peek under the hood and I wonder how much of the capitalist logic of profit and optimisation above all else has led to the ennui I currently feel. Trite? Probably. I believe I might be treading well worn ground here, but it feels original to me, and in this, I find at least some spark to hold on to.\nAnd so now I wonder why over the years I am left at having very little to say. Maybe it’s age? I’ll be 30 in a year, and I have felt the idealism I used to have start to slip away from me. I am entering my prime, but why does it feel like I am exiting it? We’ve created tools that I believe are robbing us of culture and so what is our way back? Truthfully, I don’t know.\nMy gut is telling me that bringing back sincerity again is the answer. Doing things for the sake of doing things and nothing more, nothing less, is an act of rebellion. Yes, this includes doing absolutely nothing. Be idle. Live in paradox. Pratice delicious irony, born from the internet, sincerely. How many levels are we on now? I forget. How ironic.\nIn there, I think, I might find something to say. And having written that, I find myself feeling this with the utmost sincerity."
  }
]